{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 64)]              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 3,466\nTrainable params: 3,466\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from keras import Input, layers\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Equivalent in the functional API\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n8/8 [==============================] - 0s 19ms/step - loss: 12.0441\nEpoch 2/10\n8/8 [==============================] - ETA: 0s - loss: 13.128/8 [==============================] - 0s 50ms/step - loss: 13.1236\nEpoch 3/10\n8/8 [==============================] - 0s 33ms/step - loss: 15.1772\nEpoch 4/10\n8/8 [==============================] - 0s 19ms/step - loss: 17.7597\nEpoch 5/10\n8/8 [==============================] - 0s 24ms/step - loss: 21.4344\nEpoch 6/10\n8/8 [==============================] - 0s 33ms/step - loss: 26.1615\nEpoch 7/10\n8/8 [==============================] - 0s 20ms/step - loss: 31.7835\nEpoch 8/10\n8/8 [==============================] - 0s 19ms/step - loss: 37.9756\nEpoch 9/10\n8/8 [==============================] - 0s 25ms/step - loss: 44.5488\nEpoch 10/10\n8/8 [==============================] - 0s 30ms/step - loss: 51.4604\n32/32 [==============================] - 0s 10ms/step - loss: 55.4539\n"
    }
   ],
   "source": [
    "# Compiling, training and evaluating the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ntext (InputLayer)               [(None, None)]       0                                            \n__________________________________________________________________________________________________\nquestion (InputLayer)           [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n__________________________________________________________________________________________________\nlstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n                                                                 lstm_1[0][0]                     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 500)          24500       concatenate[0][0]                \n==================================================================================================\nTotal params: 1,000,052\nTrainable params: 1,000,052\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# Functional API implementation of a two-input question-answering model\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using a list of inputs:\nEpoch 1/10\n8/8 [==============================] - 0s 50ms/step - loss: 6.2148 - acc: 0.0010\nEpoch 2/10\n8/8 [==============================] - 0s 52ms/step - loss: 6.1988 - acc: 0.0390\nEpoch 3/10\n8/8 [==============================] - 0s 35ms/step - loss: 6.1630 - acc: 0.0230\nEpoch 4/10\n8/8 [==============================] - 0s 42ms/step - loss: 6.0730 - acc: 0.0070\nEpoch 5/10\n8/8 [==============================] - 0s 51ms/step - loss: 5.9971 - acc: 0.0120\nEpoch 6/10\n8/8 [==============================] - 0s 44ms/step - loss: 5.8894 - acc: 0.0170\nEpoch 7/10\n8/8 [==============================] - 0s 35ms/step - loss: 5.7925 - acc: 0.0240\nEpoch 8/10\n8/8 [==============================] - 0s 38ms/step - loss: 5.7065 - acc: 0.0350\nEpoch 9/10\n8/8 [==============================] - 0s 39ms/step - loss: 5.6293 - acc: 0.0330\nEpoch 10/10\n8/8 [==============================] - 0s 44ms/step - loss: 5.5621 - acc: 0.0500\n\nUsing a dict of inputs\nEpoch 1/10\n8/8 [==============================] - 0s 37ms/step - loss: 5.4994 - acc: 0.0510\nEpoch 2/10\n8/8 [==============================] - 0s 40ms/step - loss: 5.4305 - acc: 0.0660\nEpoch 3/10\n8/8 [==============================] - 0s 48ms/step - loss: 5.3648 - acc: 0.0630\nEpoch 4/10\n8/8 [==============================] - 0s 62ms/step - loss: 5.3192 - acc: 0.0550\nEpoch 5/10\n8/8 [==============================] - 0s 60ms/step - loss: 5.2533 - acc: 0.0600\nEpoch 6/10\n8/8 [==============================] - 0s 49ms/step - loss: 5.2231 - acc: 0.0610\nEpoch 7/10\n8/8 [==============================] - 0s 59ms/step - loss: 5.1626 - acc: 0.0560\nEpoch 8/10\n8/8 [==============================] - 0s 58ms/step - loss: 5.0940 - acc: 0.0600\nEpoch 9/10\n8/8 [==============================] - 0s 51ms/step - loss: 5.0924 - acc: 0.0570\nEpoch 10/10\n8/8 [==============================] - 0s 57ms/step - loss: 5.0178 - acc: 0.0650\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x299a86250c8>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Feeding data to a multi-input model\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n",
    "answers = to_categorical(answers, answer_vocabulary_size)\n",
    "\n",
    "# Using a list of inputs\n",
    "print(\"Using a list of inputs:\")\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "print()\n",
    "# Using a dict of inputs (only if inputs are named)\n",
    "print(\"Using a dict of inputs\")\n",
    "model.fit({'text':text, 'question':question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-output model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groupes = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groupes, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation\n",
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# Equivalent\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weighting\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding data to a multi-output model\n",
    "# model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed acyclic graphs of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x shape: (None, 28, 28, 1)\n"
    }
   ],
   "source": [
    "# An Inception model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "print(\"x shape:\", x.shape)\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', padding='same', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature map sizes are the same\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature map sizes differ\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, None, 128)]  0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, None, 128)]  0                                            \n__________________________________________________________________________________________________\nlstm (LSTM)                     (None, 32)           20608       input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 64)           0           lstm[0][0]                       \n                                                                 lstm[1][0]                       \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            65          concatenate_2[0][0]              \n==================================================================================================\nTotal params: 20,673\nTrainable params: 20,673\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# semantic similarity between 2 sentences using layer sharing\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 250, 250, 3) 0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            [(None, 250, 250, 3) 0                                            \n__________________________________________________________________________________________________\nxception (Model)                multiple             20861480    input_4[0][0]                    \n                                                                 input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 8, 8, 4096)   0           xception[1][0]                   \n                                                                 xception[2][0]                   \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 8, 8, 10)     40970       concatenate_3[0][0]              \n==================================================================================================\nTotal params: 20,902,450\nTrainable params: 20,847,922\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# Siamese vision model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras import applications\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
    "\n",
    "predictions = layers.Dense(10, activation='softmax')(merged_features)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitdeeplearningvenv80341564c3e44c37ba47400c25aea932",
   "display_name": "Python 3.7.4 64-bit ('DeepLearning': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}